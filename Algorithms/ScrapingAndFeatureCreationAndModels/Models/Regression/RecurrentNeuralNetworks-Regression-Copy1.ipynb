{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "useful-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ranking-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.backend import sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import threading\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import time\n",
    "import multiprocessing\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import prettytable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.metrics import precision_score, make_scorer\n",
    "from keras.backend import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heard-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electric-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boolean-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranging-storage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "circular-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune_sklearn import TuneGridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-contents",
   "metadata": {},
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "passive-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    \"\"\"\n",
    "    Drops Date and Unix Date columns from the data.\n",
    "    Drops the columns which has null values more than specified null_threshold.\n",
    "    Replaces infinite values with NAN.\n",
    "    Drops the rows which has null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    null_threshold : numeric\n",
    "        numeric value describing the amount of null values that can be present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    \"\"\"\n",
    "    \n",
    "    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if null_threshold * total / 100 < data[col].isnull().sum():\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.apply(pd.to_numeric,errors='coerce')\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metropolitan-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    \"\"\"\n",
    "    Removes all the Next Day columns.\n",
    "    Removes all the non Growth Rate Columns (GR)\n",
    "    add the predictor column to list of columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    column : string\n",
    "        name of the predictor column \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    column : string\n",
    "        name of the predictor column\n",
    "    \"\"\"\n",
    "    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-denmark",
   "metadata": {},
   "source": [
    "# Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "correct-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data_r(x_train, x_test, y_train, y_test):\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],1, x_train.shape[1]))\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0],1, x_test.shape[1]))\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "\n",
    "    return (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-clothing",
   "metadata": {},
   "source": [
    "# Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "honest-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]]).astype(float)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assumed-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features]).astype(float)\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-variation",
   "metadata": {},
   "source": [
    "# RNN Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smaller-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_neural_networks(X,Y):\n",
    "    \n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state = 0)\n",
    "    x_train, x_test, y_train, y_test = split_dataset(X,Y,0.70)\n",
    "#     x_train, x_test, y_train, y_test = reshape_data(x_train, x_test, y_train, y_test)\n",
    "    x_train, x_test, y_train, y_test = reshape_data(x_train, x_test, y_train, y_test,units = 60)\n",
    "    \n",
    "    \n",
    "    epochs, batch_size = best_parameters_rnn(x_train, y_train)\n",
    "    \n",
    "    input_dim = (x_train.shape[1], x_train.shape[2])\n",
    "    print(input_dim, \"ind\")\n",
    "    \n",
    "#     model = KerasRegressor(build_fn = build_lstm, batch_size=batch_size, epochs=epochs,input_dim=input_dim)\n",
    "    \n",
    "    model = KerasRegressor(build_fn = build_lstm, input_shape=input_dim,verbose=2)\n",
    "    \n",
    "    history_lstm = model.fit(x_train,y_train,epochs = epochs,batch_size = batch_size, validation_data = (x_test,y_test),shuffle = False,verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(x_test) \n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.reshape(y_pred, (y_pred.shape[0],1))\n",
    "    \n",
    "    myres = {}\n",
    "    error = error_metrics(y_test, y_pred)\n",
    "    myres.update(error)\n",
    "    \n",
    "    c = 0\n",
    "    for a,b in zip(y_pred,y_test):\n",
    "        if a * b >= 0:\n",
    "            c += 1\n",
    "    direction = c/len(y_test)\n",
    "    \n",
    "    myres.update({\"epochs\" : epochs, \"batch_size\" : batch_size, \"layers\" : layers, \"Percentage\":direction})\n",
    "    print(\"done\")\n",
    "    return myres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mexican-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=32,return_sequences=True,input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 1,activation = 'swish'))\n",
    "    model.compile(loss='mse', optimizer=\"Adam\", metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "imposed-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(input_dim,units = 8):\n",
    "    activation='relu'\n",
    "    dropout_rate=0.2\n",
    "    init_mode='uniform'\n",
    "    weight_constraint=0 \n",
    "    optimizer='adam' \n",
    "    lr = 0.01\n",
    "    momemntum=0\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = units, input_dim = input_dim, kernel_initializer=init_mode,activation=activation))\n",
    "    model.add(Dropout(dropout_rate)) \n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='swish'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "considerable-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_parameters_rnn(X,Y):\n",
    "    \n",
    "    batch_size = [25,32,48,64,100]\n",
    "    epochs = [25,50,75,100]\n",
    "    param_grid = dict(epochs=epochs,batch_size=batch_size)\n",
    "    input_dim = (X.shape[1], X.shape[2])\n",
    "    model = KerasRegressor(build_fn = build_lstm, input_shape=input_dim,verbose = 2) \n",
    "\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,verbose=2)\n",
    "    grid_result = grid.fit(X,Y) \n",
    "    epoch = grid_result.best_params_['epochs']\n",
    "    batch_size = grid_result.best_params_['batch_size']\n",
    "    \n",
    "    return (epoch,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "reverse-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X,Y,t):\n",
    "    tr = int(len(X)*t)\n",
    "    tt = len(X) - tr\n",
    "    xtr = X[:tr]\n",
    "    xtt = X[tr:tr+tt]\n",
    "    ytr = Y[:tr]\n",
    "    ytt = Y[tr:tr+tt]\n",
    "    return (xtr,xtt,ytr,ytt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "operational-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(x_train, x_test, y_train, y_test,units = 60):\n",
    "    my_x_train = list()\n",
    "    my_y_train = list()\n",
    "    my_x_test = list()\n",
    "    my_y_test = list()\n",
    "    for i in range(x_train.shape[0]-units):\n",
    "        my_x_train.append(x_train.iloc[i:i+units,:])\n",
    "        my_y_train.append(y_train.iloc[i+units,])\n",
    "    \n",
    "    my_x_train = np.array(my_x_train)\n",
    "    my_x_train = np.reshape(my_x_train,(my_x_train.shape[0],my_x_train.shape[1],my_x_train.shape[2]))\n",
    "    \n",
    "    my_y_train = np.array(my_y_train)\n",
    "    my_y_train = np.reshape(my_y_train,(my_y_train.shape[0],1))\n",
    "    \n",
    "    for i in range(x_test.shape[0]-units):\n",
    "        my_x_test.append(x_test.iloc[i:i+units,:])\n",
    "        my_y_test.append(y_test.iloc[i+units,])\n",
    "        \n",
    "    my_x_test = np.array(my_x_test)\n",
    "    my_x_test = np.reshape(my_x_test,(my_x_test.shape[0],my_x_test.shape[1],my_x_test.shape[2]))\n",
    "    \n",
    "    my_y_test = np.array(my_y_test)\n",
    "    my_y_test = np.reshape(my_y_test,(my_y_test.shape[0],1))\n",
    "    \n",
    "    return (my_x_train, my_x_test, my_y_train, my_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "shaped-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metrics(y_true, y_pred):\n",
    "    rmse = sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    return {\"RMSE\":rmse,\"MAE\":mae,\"MSE\":mse, \"rsquared_adj\" : r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-static",
   "metadata": {},
   "source": [
    "# Finding results from each set of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bronze-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_RNN(df, column, method, name, results):\n",
    "    print(\"RNN Model fitted using columns obtained from feature importance using \" + method + \" : \")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column]\n",
    "    \n",
    "    model_result = recurrent_neural_networks(X, Y)\n",
    "        \n",
    "    results[\"RNN_Regression_FI_\" + method] = model_result[\"Percentage\"]\n",
    "    \n",
    "    print(\"Maximum percentage of correct direction : \", model_result[\"Percentage\"])\n",
    "    \n",
    "    create_pretty_table(name , \"RNN_Regression\", method , model_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "signed-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_ForwardSelection(df1, name, column, results):\n",
    "    print(\"Features Importance using Forward Selection Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"ForwardSelection\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    forward_features = forward_selection(X,Y)\n",
    "    print(\"Features obtained from Forward Selection method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(forward_features)\n",
    "    if (len(forward_features) != 0):\n",
    "        forward_features.append(column)\n",
    "        df_fs = df1[forward_features]\n",
    "        fit_RNN(df_fs, column, method, name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "electric-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_BackwardElimination(df1, name, column, results):\n",
    "    print(\"Features Importance using Backward Elimination Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"BackwardElimination\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    backward_features = backward_elimination(X,Y)\n",
    "    print(\"Features obtained from Backward Elimination method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(backward_features)\n",
    "    if (len(backward_features) != 0):\n",
    "        backward_features.append(column)\n",
    "        df_be = df1[backward_features]\n",
    "        fit_RNN(df_be, column, method, name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "integral-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_AllFeatures(df1, name, column, results):\n",
    "    print(\"All Features are considered : \")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"AllFeaturesConsideration\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    all_features = list(X.columns)\n",
    "    print(\"All Features are --->>\") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(all_features)\n",
    "    if (len(all_features) != 0):\n",
    "        all_features.append(column)\n",
    "        df_all = df1[all_features]\n",
    "        fit_RNN(df_all, column, method, name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "signed-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_each_set(data, name, final_df):\n",
    "    df = pre_process_data(data, 60)\n",
    "    column = \"Next Day Close Price GR\"\n",
    "    (df1, column) = dependent_column(df, column)\n",
    "    results = {}\n",
    "    get_results_from_FI_ForwardSelection(df1, name, column, results)\n",
    "    get_results_from_FI_BackwardElimination(df1, name, column, results)\n",
    "    get_results_from_FI_AllFeatures(df1, name, column, results)\n",
    "    sorted_results = sorted(results.items(), key=lambda item: item[1])\n",
    "    max_row = {'Company' : name[2 : 8] + \"-\" + companies[name[2 : 8]], 'Model' : 'RNN-Regression', 'Method' : sorted_results[-1][0], 'Percentage' : sorted_results[-1][1]}\n",
    "    final_df = final_df.append(max_row, ignore_index = True)\n",
    "    print(\"Maximum correct direction values are obtained for {} with a percentage of {}.\".format(sorted_results[-1][0], sorted_results[-1][1]))\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-seating",
   "metadata": {},
   "source": [
    "# Process of getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "canadian-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_table(name, model, method, result):\n",
    "    values = [name[2 : 8 ] + \"-\" + companies[name[2 : 8]], method] + [round(v, 6) if (not isinstance(v, str)) else v for k,v in result.items()]\n",
    "    tables[model].add_row(values)\n",
    "    tables[model].title = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ignored-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['Company','Method','RMSE','MAE','MSE','rsquared_adj','epochs','batch_size','layers','Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "juvenile-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = {\"500112\" : \"SBIN\" ,\n",
    "\"500325\" : \"RELIANCE INDUSTRIES LTD\",\n",
    "\"532540\" : \"TATA CONSULTANCY SERVICES LTD\" ,\n",
    "\"500209\" : \"INFOSYS LTD\", \n",
    "\"532174\" : \"ICICI BANK LTD\", \n",
    "\"507685\" : \"WIPRO LTD\", \n",
    "\"530965\" : \"INDIAN OIL CORPORATION LTD\", \n",
    "\"500182\" : \"HERO MOTOCORP LTD\", \n",
    "\"532210\" : \"CITY UNION BANK LTD\", \n",
    "\"500180\" : \"HDFC Bank Ltd\",\n",
    "\"500680\" : \"PFIZER LTD\", \n",
    "\"506395\" : \"COROMANDEL iNTERNATIONAL LTD\",\n",
    "\"500770\" : \"TATA CHEMICALS LTD\", \n",
    "\"500085\" : \"CHAMBAL FERTILISERS & CHEMICALS LTD\", \n",
    "\"501425\" : \"BOMBAY BURMAH TRADING CORP.LTD\", \n",
    "\"532899\" : \"KAVERI SEED COMPANY LTD\", \n",
    "\"537291\" : \"NATH BIO-GENES (INDIA) LTD\", \n",
    "\"500790\" : \"NESTLE INDIA LTD\", \n",
    "\"500825\" : \"BRITANNIA INDUSTRIES LTD\", \n",
    "\"533155\" : \"JUBILANT FOODWORKS LTD\", \n",
    "\"533287\" : \"ZEE LEARN LTD\", \n",
    "\"533260\" : \"CAREER POINT LTD\", \n",
    "\"539921\" : \"SHANTI EDUCATIONAL INITIATIVES LTD\", \n",
    "\"542602\" : \"EMBASSY OFFICE PARKS REIT\", \n",
    "\"543217\" : \"MINDSPACE BUSINESS PARKS REIT\", \n",
    "\"543261\" : \"BROOKFIELD INDIA REAL ESTATE TRUST REIT\", \n",
    "\"532538\" : \"ULTRATECH CEMENT LTD\", \n",
    "\"500387\" : \"SHREE CEMENT LTD\", \n",
    "\"500425\" : \"AMBUJA CEMENTS LTD\", \n",
    "\"532689\" : \"PVR LTD\", \n",
    "\"532706\" : \"INOX LEISURE LTD\", \n",
    "\"532163\" : \"SAREGAMA INDIA LTD\", \n",
    "\"524715\" : \"SUN PHARMACEUTICAL INDUSTRIES LTD\", \n",
    "\"532488\" : \"DIVI'S LABORATORIES LTD\",\n",
    "\"500124\" : \"DR.REDDY'S LABORATORIES LTD\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "serial-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RNN_Regression\"]\n",
    "tables = {model:PrettyTable() for model in models}\n",
    "for name,table in tables.items():\n",
    "    table.field_names = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daily-defense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>GNN-Regression</td>\n",
       "      <td>GNN_Regression_FI_AllFeaturesConsideration_std...</td>\n",
       "      <td>0.654034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>KNN-Regression</td>\n",
       "      <td>KNN_Regression_FI_BackwardElimination_</td>\n",
       "      <td>0.540342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>RidgeFIFValue1</td>\n",
       "      <td>0.506112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>LinearFIBackwardElimination</td>\n",
       "      <td>0.501222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>LassoFIFValue10</td>\n",
       "      <td>0.497555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>LinearFICoefficients0.1</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>RidgeFICoefficients0.1</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>KNN-Regression</td>\n",
       "      <td>KNN_Regression_FI_AllFeaturesConsideration_</td>\n",
       "      <td>0.530769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>GNN-Regression</td>\n",
       "      <td>GNN_Regression_FI_ForwardSelection_stds_0.9</td>\n",
       "      <td>0.507692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>SVR</td>\n",
       "      <td>SVR_FI_FValue_1</td>\n",
       "      <td>0.484615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company              Model  \\\n",
       "0    500085-CHAMBAL FERTILISERS & CHEMICALS LTD     GNN-Regression   \n",
       "1    500085-CHAMBAL FERTILISERS & CHEMICALS LTD     KNN-Regression   \n",
       "2    500085-CHAMBAL FERTILISERS & CHEMICALS LTD   Ridge Regression   \n",
       "3    500085-CHAMBAL FERTILISERS & CHEMICALS LTD  Linear Regression   \n",
       "4    500085-CHAMBAL FERTILISERS & CHEMICALS LTD   Lasso Regression   \n",
       "..                                          ...                ...   \n",
       "219            542602-EMBASSY OFFICE PARKS REIT  Linear Regression   \n",
       "220            542602-EMBASSY OFFICE PARKS REIT   Ridge Regression   \n",
       "221            542602-EMBASSY OFFICE PARKS REIT     KNN-Regression   \n",
       "222            542602-EMBASSY OFFICE PARKS REIT     GNN-Regression   \n",
       "223            542602-EMBASSY OFFICE PARKS REIT                SVR   \n",
       "\n",
       "                                                Method  Percentage  \n",
       "0    GNN_Regression_FI_AllFeaturesConsideration_std...    0.654034  \n",
       "1               KNN_Regression_FI_BackwardElimination_    0.540342  \n",
       "2                                       RidgeFIFValue1    0.506112  \n",
       "3                          LinearFIBackwardElimination    0.501222  \n",
       "4                                      LassoFIFValue10    0.497555  \n",
       "..                                                 ...         ...  \n",
       "219                            LinearFICoefficients0.1    0.538462  \n",
       "220                             RidgeFICoefficients0.1    0.538462  \n",
       "221        KNN_Regression_FI_AllFeaturesConsideration_    0.530769  \n",
       "222        GNN_Regression_FI_ForwardSelection_stds_0.9    0.507692  \n",
       "223                                    SVR_FI_FValue_1    0.484615  \n",
       "\n",
       "[224 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Final_Results_df.csv\")\n",
    "# final_df.drop('Unnamed: 0', inplace = True, axis = 'columns')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-jason",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For stock :  500085\n",
      "#################################################################################################################\n",
      "Features Importance using Forward Selection Method\n",
      "*****************************************************************************************\n",
      "Features obtained from Forward Selection method : \n",
      "--------------------------------------\n",
      "['Beta GR']\n",
      "RNN Model fitted using columns obtained from feature importance using ForwardSelection : \n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock\")):\n",
    "    if filename.startswith(\"gr500085\"):\n",
    "        df_rnn = pd.read_csv(os.path.join(path,\"Data\\Stock\\\\\" + filename))\n",
    "        name = os.path.join(path, \"Data\\Stock\\\\\" + filename).split(\"\\\\\")[-1]\n",
    "        stock = name[2 : 8]\n",
    "        fd_df = pd.DataFrame(columns = final_df.columns)\n",
    "        print(\"For stock : \", stock)\n",
    "        print(\"#################################################################################################################\")\n",
    "        f_df = get_results_from_each_set(df_rnn, name, fd_df)\n",
    "        final_df = final_df.append(f_df, ignore_index = True)\n",
    "        print(\"#################################################################################################################\")\n",
    "        break\n",
    "        \n",
    "# final_df = final_df.sort_values(by = ['Company', 'Percentage'], ascending = [True, False])\n",
    "# final_df.to_csv('C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Final_Results_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,table in tables.items():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
